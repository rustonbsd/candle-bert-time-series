# tldr
```

const SEQUENCE_LENGTH: usize = 240;
const MODEL_DIMS: usize = 384;
const NUM_LAYERS: usize = 12;
const NUM_HEADS: usize = 12;

ðŸ“ˆ SUMMARY STATISTICS (INDIVIDUAL MASKING, EVENLY SPACED SAMPLES):
======================================================================
ðŸŒ ALL CRYPTOS (111 total) - INDIVIDUAL MASKING RESULTS:
  - Mean correlation: 0.0061
  - Max correlation: 0.1702
  - Min correlation: -0.1252
  - Strong signals (|corr| > 0.1): 9 (8.1%)
  - Weak signals (0.05 < |corr| â‰¤ 0.1): 35 (31.5%)
  - No signal (|corr| â‰¤ 0.05): 67 (60.4%)
```

# Loss
```
Epoch 1 Summary:
  Train Loss: 0.0052582812
  Val Loss:   0.0000261646

Epoch 2 Summary:
  Train Loss: 0.0001551194
  Val Loss:   0.0001105674

Epoch 4 Summary:
  Train Loss: 0.0001524779
  Val Loss:   0.0000494270

Epoch 5 Summary:
  Train Loss: 0.0001490160
  Val Loss:   0.0001895587

Epoch 6 Summary:
  Train Loss: 0.0001486200
  Val Loss:   0.0000924188

Epoch 7 Summary:
  Train Loss: 0.0001459790
  Val Loss:   0.0002906480

Epoch 8 Summary:
  Train Loss: 0.0001503852
  Val Loss:   0.0002636451

Epoch 9 Summary:
  Train Loss: 0.0001442942
  Val Loss:   0.0000744212
```

# STDOUT
```
ðŸ“Š QUANTITATIVE ANALYSIS - Cross-Sectional Crypto Inference
======================================================================
This analysis focuses on inferring currency movements from others,
not next-step prediction. Pure analysis without trading simulation.
======================================================================
Using device: Cuda(CudaDevice(DeviceId(1)))

Loading cryptocurrency data...
Data loaded. Shape: 2278676 rows Ã— 111 columns
Detected 111 cryptocurrencies
Data tensor shape: [2278676, 111]
Data loaded: 111 assets, 341802 test timesteps

ðŸ¤– Loading trained model...
âœ… Model loaded from: current_model_large_r2_ep9.safetensors
ðŸŽ² Using random crypto selection
ðŸŽ¯ Cross-sectional setup:
  - Blacked out cryptos (to predict): [11, 24, 60, 65, 75, 86, 89, 96]
  - Predictor cryptos: 103 assets

ðŸ” CORRELATION ANALYSIS FOR ALL CRYPTOS (INDIVIDUAL MASKING)
======================================================================
Note: Each crypto is masked individually while all others use real data
Using 499 evenly spaced samples from 0 to 341801 (step size: 683)

ðŸ“Š CRYPTO_0 (Index: 0) - INDIVIDUALLY MASKED:
  - Correlation: -0.0412
  - Mean predicted: -0.003514
  - Mean actual: -0.000006
  - Mean divergence: -0.003508
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_1 (Index: 1) - INDIVIDUALLY MASKED:
  - Correlation: -0.0038
  - Mean predicted: -0.001370
  - Mean actual: -0.000010
  - Mean divergence: -0.001360
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_2 (Index: 2) - INDIVIDUALLY MASKED:
  - Correlation: 0.0766
  - Mean predicted: 0.000251
  - Mean actual: -0.000008
  - Mean divergence: 0.000260
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_3 (Index: 3) - INDIVIDUALLY MASKED:
  - Correlation: 0.0404
  - Mean predicted: 0.000263
  - Mean actual: -0.000031
  - Mean divergence: 0.000294
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_4 (Index: 4) - INDIVIDUALLY MASKED:
  - Correlation: -0.0730
  - Mean predicted: -0.000644
  - Mean actual: -0.000029
  - Mean divergence: -0.000616
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_5 (Index: 5) - INDIVIDUALLY MASKED:
  - Correlation: 0.0164
  - Mean predicted: 0.000118
  - Mean actual: -0.000019
  - Mean divergence: 0.000137
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_6 (Index: 6) - INDIVIDUALLY MASKED:
  - Correlation: -0.0519
  - Mean predicted: -0.002484
  - Mean actual: -0.000056
  - Mean divergence: -0.002427
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_7 (Index: 7) - INDIVIDUALLY MASKED:
  - Correlation: -0.0196
  - Mean predicted: -0.001297
  - Mean actual: 0.000067
  - Mean divergence: -0.001363
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_8 (Index: 8) - INDIVIDUALLY MASKED:
  - Correlation: 0.1157
  - Mean predicted: 0.000245
  - Mean actual: -0.000000
  - Mean divergence: 0.000245
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_9 (Index: 9) - INDIVIDUALLY MASKED:
  - Correlation: 0.0521
  - Mean predicted: -0.000486
  - Mean actual: 0.000030
  - Mean divergence: -0.000516
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_10 (Index: 10) - INDIVIDUALLY MASKED:
  - Correlation: -0.0097
  - Mean predicted: -0.006863
  - Mean actual: -0.000032
  - Mean divergence: -0.006832
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_11 (Index: 11) - INDIVIDUALLY MASKED:
  - Correlation: 0.0985
  - Mean predicted: 0.003555
  - Mean actual: -0.000012
  - Mean divergence: 0.003568
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_12 (Index: 12) - INDIVIDUALLY MASKED:
  - Correlation: 0.0930
  - Mean predicted: 0.000329
  - Mean actual: 0.000002
  - Mean divergence: 0.000327
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_13 (Index: 13) - INDIVIDUALLY MASKED:
  - Correlation: -0.0686
  - Mean predicted: -0.001190
  - Mean actual: 0.000021
  - Mean divergence: -0.001211
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_14 (Index: 14) - INDIVIDUALLY MASKED:
  - Correlation: 0.0044
  - Mean predicted: 0.002505
  - Mean actual: 0.000066
  - Mean divergence: 0.002439
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_15 (Index: 15) - INDIVIDUALLY MASKED:
  - Correlation: 0.0509
  - Mean predicted: 0.001123
  - Mean actual: -0.000035
  - Mean divergence: 0.001158
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_16 (Index: 16) - INDIVIDUALLY MASKED:
  - Correlation: 0.1633
  - Mean predicted: 0.000597
  - Mean actual: -0.000098
  - Mean divergence: 0.000696
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_17 (Index: 17) - INDIVIDUALLY MASKED:
  - Correlation: -0.0488
  - Mean predicted: 0.000223
  - Mean actual: 0.000010
  - Mean divergence: 0.000213
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_18 (Index: 18) - INDIVIDUALLY MASKED:
  - Correlation: -0.0041
  - Mean predicted: -0.000208
  - Mean actual: -0.000005
  - Mean divergence: -0.000203
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_19 (Index: 19) - INDIVIDUALLY MASKED:
  - Correlation: 0.0167
  - Mean predicted: -0.002644
  - Mean actual: 0.000014
  - Mean divergence: -0.002658
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_20 (Index: 20) - INDIVIDUALLY MASKED:
  - Correlation: 0.0474
  - Mean predicted: 0.001005
  - Mean actual: -0.000008
  - Mean divergence: 0.001013
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_21 (Index: 21) - INDIVIDUALLY MASKED:
  - Correlation: -0.0307
  - Mean predicted: -0.000628
  - Mean actual: 0.000016
  - Mean divergence: -0.000644
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_22 (Index: 22) - INDIVIDUALLY MASKED:
  - Correlation: 0.0244
  - Mean predicted: 0.005499
  - Mean actual: -0.000022
  - Mean divergence: 0.005522
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_23 (Index: 23) - INDIVIDUALLY MASKED:
  - Correlation: 0.0671
  - Mean predicted: -0.001362
  - Mean actual: 0.000029
  - Mean divergence: -0.001392
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_24 (Index: 24) - INDIVIDUALLY MASKED:
  - Correlation: -0.0572
  - Mean predicted: 0.000263
  - Mean actual: 0.000007
  - Mean divergence: 0.000256
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_25 (Index: 25) - INDIVIDUALLY MASKED:
  - Correlation: -0.0234
  - Mean predicted: -0.204441
  - Mean actual: -0.000036
  - Mean divergence: -0.204405
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_26 (Index: 26) - INDIVIDUALLY MASKED:
  - Correlation: 0.0070
  - Mean predicted: -0.035465
  - Mean actual: 0.000017
  - Mean divergence: -0.035481
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_27 (Index: 27) - INDIVIDUALLY MASKED:
  - Correlation: -0.0208
  - Mean predicted: -0.000381
  - Mean actual: 0.000061
  - Mean divergence: -0.000442
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_28 (Index: 28) - INDIVIDUALLY MASKED:
  - Correlation: 0.0795
  - Mean predicted: 0.000550
  - Mean actual: -0.000003
  - Mean divergence: 0.000554
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_29 (Index: 29) - INDIVIDUALLY MASKED:
  - Correlation: -0.0465
  - Mean predicted: -0.013117
  - Mean actual: -0.000013
  - Mean divergence: -0.013104
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_30 (Index: 30) - INDIVIDUALLY MASKED:
  - Correlation: -0.0712
  - Mean predicted: -0.009043
  - Mean actual: -0.000097
  - Mean divergence: -0.008946
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_31 (Index: 31) - INDIVIDUALLY MASKED:
  - Correlation: -0.0591
  - Mean predicted: -0.000437
  - Mean actual: -0.000113
  - Mean divergence: -0.000325
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_32 (Index: 32) - INDIVIDUALLY MASKED:
  - Correlation: 0.0520
  - Mean predicted: 0.000257
  - Mean actual: 0.000019
  - Mean divergence: 0.000238
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_33 (Index: 33) - INDIVIDUALLY MASKED:
  - Correlation: -0.0056
  - Mean predicted: 0.010235
  - Mean actual: 0.000022
  - Mean divergence: 0.010213
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_34 (Index: 34) - INDIVIDUALLY MASKED:
  - Correlation: -0.0052
  - Mean predicted: -0.025676
  - Mean actual: 0.000064
  - Mean divergence: -0.025739
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_35 (Index: 35) - INDIVIDUALLY MASKED:
  - Correlation: 0.0806
  - Mean predicted: 0.000410
  - Mean actual: 0.000076
  - Mean divergence: 0.000333
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_36 (Index: 36) - INDIVIDUALLY MASKED:
  - Correlation: -0.0129
  - Mean predicted: -0.000703
  - Mean actual: 0.000068
  - Mean divergence: -0.000772
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_37 (Index: 37) - INDIVIDUALLY MASKED:
  - Correlation: 0.0019
  - Mean predicted: 0.000366
  - Mean actual: 0.000014
  - Mean divergence: 0.000352
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_38 (Index: 38) - INDIVIDUALLY MASKED:
  - Correlation: -0.0097
  - Mean predicted: -0.004530
  - Mean actual: -0.000026
  - Mean divergence: -0.004504
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_39 (Index: 39) - INDIVIDUALLY MASKED:
  - Correlation: 0.0208
  - Mean predicted: -0.000200
  - Mean actual: 0.000080
  - Mean divergence: -0.000280
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_40 (Index: 40) - INDIVIDUALLY MASKED:
  - Correlation: -0.0397
  - Mean predicted: -0.004359
  - Mean actual: -0.000052
  - Mean divergence: -0.004307
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_41 (Index: 41) - INDIVIDUALLY MASKED:
  - Correlation: 0.0593
  - Mean predicted: 0.000966
  - Mean actual: 0.000048
  - Mean divergence: 0.000918
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_42 (Index: 42) - INDIVIDUALLY MASKED:
  - Correlation: 0.0643
  - Mean predicted: -0.055637
  - Mean actual: -0.000004
  - Mean divergence: -0.055634
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_43 (Index: 43) - INDIVIDUALLY MASKED:
  - Correlation: -0.0635
  - Mean predicted: -0.015383
  - Mean actual: 0.000108
  - Mean divergence: -0.015491
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_44 (Index: 44) - INDIVIDUALLY MASKED:
  - Correlation: 0.0369
  - Mean predicted: -0.008469
  - Mean actual: -0.000048
  - Mean divergence: -0.008420
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_45 (Index: 45) - INDIVIDUALLY MASKED:
  - Correlation: -0.0378
  - Mean predicted: -0.000183
  - Mean actual: -0.000005
  - Mean divergence: -0.000178
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_46 (Index: 46) - INDIVIDUALLY MASKED:
  - Correlation: -0.0649
  - Mean predicted: -0.000535
  - Mean actual: 0.000007
  - Mean divergence: -0.000542
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_47 (Index: 47) - INDIVIDUALLY MASKED:
  - Correlation: 0.0700
  - Mean predicted: 0.027589
  - Mean actual: 0.000015
  - Mean divergence: 0.027573
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_48 (Index: 48) - INDIVIDUALLY MASKED:
  - Correlation: -0.0624
  - Mean predicted: -0.001973
  - Mean actual: 0.000044
  - Mean divergence: -0.002016
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_49 (Index: 49) - INDIVIDUALLY MASKED:
  - Correlation: -0.0133
  - Mean predicted: 0.003326
  - Mean actual: 0.000015
  - Mean divergence: 0.003311
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_50 (Index: 50) - INDIVIDUALLY MASKED:
  - Correlation: -0.0067
  - Mean predicted: -0.000250
  - Mean actual: -0.000072
  - Mean divergence: -0.000178
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_51 (Index: 51) - INDIVIDUALLY MASKED:
  - Correlation: 0.0334
  - Mean predicted: 0.003464
  - Mean actual: 0.000002
  - Mean divergence: 0.003462
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_52 (Index: 52) - INDIVIDUALLY MASKED:
  - Correlation: -0.0316
  - Mean predicted: -0.006446
  - Mean actual: 0.000015
  - Mean divergence: -0.006461
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_53 (Index: 53) - INDIVIDUALLY MASKED:
  - Correlation: 0.0272
  - Mean predicted: 0.006743
  - Mean actual: -0.000018
  - Mean divergence: 0.006761
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_54 (Index: 54) - INDIVIDUALLY MASKED:
  - Correlation: -0.0652
  - Mean predicted: -0.001308
  - Mean actual: -0.000014
  - Mean divergence: -0.001294
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_55 (Index: 55) - INDIVIDUALLY MASKED:
  - Correlation: 0.0615
  - Mean predicted: 0.000048
  - Mean actual: -0.000047
  - Mean divergence: 0.000095
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_56 (Index: 56) - INDIVIDUALLY MASKED:
  - Correlation: 0.0700
  - Mean predicted: 0.000891
  - Mean actual: 0.000064
  - Mean divergence: 0.000827
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_57 (Index: 57) - INDIVIDUALLY MASKED:
  - Correlation: 0.0329
  - Mean predicted: 0.005666
  - Mean actual: -0.000016
  - Mean divergence: 0.005682
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_58 (Index: 58) - INDIVIDUALLY MASKED:
  - Correlation: -0.1252
  - Mean predicted: 0.003109
  - Mean actual: -0.000027
  - Mean divergence: 0.003136
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_59 (Index: 59) - INDIVIDUALLY MASKED:
  - Correlation: -0.0333
  - Mean predicted: -0.013639
  - Mean actual: -0.000013
  - Mean divergence: -0.013627
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_60 (Index: 60) - INDIVIDUALLY MASKED:
  - Correlation: 0.0638
  - Mean predicted: 0.000079
  - Mean actual: 0.000029
  - Mean divergence: 0.000050
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal
ðŸ“Š CRYPTO_61 (Index: 61) - INDIVIDUALLY MASKED:
  - Correlation: -0.0182
  - Mean predicted: 0.000366
  - Mean actual: -0.000004
  - Mean divergence: 0.000371
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_62 (Index: 62) - INDIVIDUALLY MASKED:
  - Correlation: 0.0237
  - Mean predicted: 0.002612
  - Mean actual: 0.000052
  - Mean divergence: 0.002560
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_63 (Index: 63) - INDIVIDUALLY MASKED:
  - Correlation: 0.0344
  - Mean predicted: -0.002842
  - Mean actual: 0.000056
  - Mean divergence: -0.002898
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_64 (Index: 64) - INDIVIDUALLY MASKED:
  - Correlation: -0.0912
  - Mean predicted: 0.002437
  - Mean actual: -0.000024
  - Mean divergence: 0.002461
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_65 (Index: 65) - INDIVIDUALLY MASKED:
  - Correlation: 0.0331
  - Mean predicted: -0.000226
  - Mean actual: -0.000004
  - Mean divergence: -0.000222
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_66 (Index: 66) - INDIVIDUALLY MASKED:
  - Correlation: 0.0433
  - Mean predicted: -0.000759
  - Mean actual: -0.000041
  - Mean divergence: -0.000719
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_67 (Index: 67) - INDIVIDUALLY MASKED:
  - Correlation: -0.0545
  - Mean predicted: -0.002038
  - Mean actual: 0.000016
  - Mean divergence: -0.002054
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_68 (Index: 68) - INDIVIDUALLY MASKED:
  - Correlation: -0.0718
  - Mean predicted: 0.000049
  - Mean actual: -0.000114
  - Mean divergence: 0.000163
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_69 (Index: 69) - INDIVIDUALLY MASKED:
  - Correlation: 0.0733
  - Mean predicted: 0.000911
  - Mean actual: 0.000005
  - Mean divergence: 0.000907
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_70 (Index: 70) - INDIVIDUALLY MASKED:
  - Correlation: -0.0059
  - Mean predicted: 0.044728
  - Mean actual: -0.000013
  - Mean divergence: 0.044741
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_71 (Index: 71) - INDIVIDUALLY MASKED:
  - Correlation: -0.0401
  - Mean predicted: 0.000588
  - Mean actual: -0.000015
  - Mean divergence: 0.000603
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_72 (Index: 72) - INDIVIDUALLY MASKED:
  - Correlation: -0.0353
  - Mean predicted: -0.000423
  - Mean actual: -0.000021
  - Mean divergence: -0.000402
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_73 (Index: 73) - INDIVIDUALLY MASKED:
  - Correlation: 0.0308
  - Mean predicted: 0.000042
  - Mean actual: 0.000028
  - Mean divergence: 0.000014
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_74 (Index: 74) - INDIVIDUALLY MASKED:
  - Correlation: 0.1017
  - Mean predicted: -0.001360
  - Mean actual: -0.000044
  - Mean divergence: -0.001316
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_75 (Index: 75) - INDIVIDUALLY MASKED:
  - Correlation: 0.0336
  - Mean predicted: 0.022149
  - Mean actual: 0.000096
  - Mean divergence: 0.022053
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_76 (Index: 76) - INDIVIDUALLY MASKED:
  - Correlation: -0.0139
  - Mean predicted: 0.010887
  - Mean actual: -0.000016
  - Mean divergence: 0.010902
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_77 (Index: 77) - INDIVIDUALLY MASKED:
  - Correlation: -0.0019
  - Mean predicted: -0.000314
  - Mean actual: -0.000047
  - Mean divergence: -0.000267
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_78 (Index: 78) - INDIVIDUALLY MASKED:
  - Correlation: -0.0611
  - Mean predicted: -0.000120
  - Mean actual: 0.000081
  - Mean divergence: -0.000201
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_79 (Index: 79) - INDIVIDUALLY MASKED:
  - Correlation: -0.0099
  - Mean predicted: -0.006038
  - Mean actual: 0.000063
  - Mean divergence: -0.006101
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_80 (Index: 80) - INDIVIDUALLY MASKED:
  - Correlation: 0.0496
  - Mean predicted: -0.005434
  - Mean actual: 0.000009
  - Mean divergence: -0.005443
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_81 (Index: 81) - INDIVIDUALLY MASKED:
  - Correlation: -0.0857
  - Mean predicted: -0.044275
  - Mean actual: -0.000012
  - Mean divergence: -0.044263
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_82 (Index: 82) - INDIVIDUALLY MASKED:
  - Correlation: -0.0149
  - Mean predicted: -0.000189
  - Mean actual: 0.000039
  - Mean divergence: -0.000228
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_83 (Index: 83) - INDIVIDUALLY MASKED:
  - Correlation: -0.0252
  - Mean predicted: 0.000013
  - Mean actual: 0.000044
  - Mean divergence: -0.000031
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_84 (Index: 84) - INDIVIDUALLY MASKED:
  - Correlation: -0.0737
  - Mean predicted: -0.000195
  - Mean actual: 0.000000
  - Mean divergence: -0.000195
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_85 (Index: 85) - INDIVIDUALLY MASKED:
  - Correlation: -0.0114
  - Mean predicted: 0.000972
  - Mean actual: -0.000006
  - Mean divergence: 0.000978
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_86 (Index: 86) - INDIVIDUALLY MASKED:
  - Correlation: 0.0069
  - Mean predicted: 0.003217
  - Mean actual: 0.000006
  - Mean divergence: 0.003212
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_87 (Index: 87) - INDIVIDUALLY MASKED:
  - Correlation: 0.1702
  - Mean predicted: -0.000170
  - Mean actual: -0.000116
  - Mean divergence: -0.000054
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_88 (Index: 88) - INDIVIDUALLY MASKED:
  - Correlation: -0.0138
  - Mean predicted: -0.023545
  - Mean actual: -0.000024
  - Mean divergence: -0.023521
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_89 (Index: 89) - INDIVIDUALLY MASKED:
  - Correlation: 0.0010
  - Mean predicted: -0.000478
  - Mean actual: 0.000027
  - Mean divergence: -0.000505
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_90 (Index: 90) - INDIVIDUALLY MASKED:
  - Correlation: -0.0491
  - Mean predicted: -0.010811
  - Mean actual: -0.000040
  - Mean divergence: -0.010771
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_91 (Index: 91) - INDIVIDUALLY MASKED:
  - Correlation: -0.0459
  - Mean predicted: 0.012556
  - Mean actual: 0.000042
  - Mean divergence: 0.012514
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_92 (Index: 92) - INDIVIDUALLY MASKED:
  - Correlation: 0.0586
  - Mean predicted: 0.000016
  - Mean actual: 0.000023
  - Mean divergence: -0.000007
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_93 (Index: 93) - INDIVIDUALLY MASKED:
  - Correlation: 0.0257
  - Mean predicted: 0.001044
  - Mean actual: -0.000067
  - Mean divergence: 0.001111
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_94 (Index: 94) - INDIVIDUALLY MASKED:
  - Correlation: 0.1110
  - Mean predicted: -0.000400
  - Mean actual: -0.000015
  - Mean divergence: -0.000385
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_95 (Index: 95) - INDIVIDUALLY MASKED:
  - Correlation: 0.0214
  - Mean predicted: -0.000132
  - Mean actual: 0.000069
  - Mean divergence: -0.000201
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_96 (Index: 96) - INDIVIDUALLY MASKED:
  - Correlation: 0.1273
  - Mean predicted: -0.000889
  - Mean actual: -0.000087
  - Mean divergence: -0.000802
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_97 (Index: 97) - INDIVIDUALLY MASKED:
  - Correlation: -0.1196
  - Mean predicted: 0.000221
  - Mean actual: -0.000012
  - Mean divergence: 0.000233
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_98 (Index: 98) - INDIVIDUALLY MASKED:
  - Correlation: -0.0051
  - Mean predicted: -0.001497
  - Mean actual: 0.000041
  - Mean divergence: -0.001538
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_99 (Index: 99) - INDIVIDUALLY MASKED:
  - Correlation: 0.0218
  - Mean predicted: -0.000127
  - Mean actual: -0.000049
  - Mean divergence: -0.000078
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_100 (Index: 100) - INDIVIDUALLY MASKED:
  - Correlation: 0.0825
  - Mean predicted: 0.001825
  - Mean actual: 0.000056
  - Mean divergence: 0.001769
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_101 (Index: 101) - INDIVIDUALLY MASKED:
  - Correlation: 0.0326
  - Mean predicted: 0.004846
  - Mean actual: 0.000100
  - Mean divergence: 0.004746
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_102 (Index: 102) - INDIVIDUALLY MASKED:
  - Correlation: -0.0210
  - Mean predicted: -0.003372
  - Mean actual: -0.000008
  - Mean divergence: -0.003365
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_103 (Index: 103) - INDIVIDUALLY MASKED:
  - Correlation: -0.0123
  - Mean predicted: 0.004926
  - Mean actual: 0.000023
  - Mean divergence: 0.004903
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_104 (Index: 104) - INDIVIDUALLY MASKED:
  - Correlation: -0.0447
  - Mean predicted: 0.017815
  - Mean actual: -0.000042
  - Mean divergence: 0.017857
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_105 (Index: 105) - INDIVIDUALLY MASKED:
  - Correlation: 0.0671
  - Mean predicted: -0.000385
  - Mean actual: -0.000065
  - Mean divergence: -0.000321
  - Data points: 499
  âš ï¸  Weak cross-sectional predictive signal

ðŸ“Š CRYPTO_106 (Index: 106) - INDIVIDUALLY MASKED:
  - Correlation: -0.0007
  - Mean predicted: -0.003730
  - Mean actual: 0.000001
  - Mean divergence: -0.003731
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_107 (Index: 107) - INDIVIDUALLY MASKED:
  - Correlation: -0.0399
  - Mean predicted: 0.000611
  - Mean actual: -0.000093
  - Mean divergence: 0.000704
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_108 (Index: 108) - INDIVIDUALLY MASKED:
  - Correlation: 0.1098
  - Mean predicted: -0.004027
  - Mean actual: 0.000104
  - Mean divergence: -0.004131
  - Data points: 499
  âœ… Strong cross-sectional predictive signal

ðŸ“Š CRYPTO_109 (Index: 109) - INDIVIDUALLY MASKED:
  - Correlation: -0.0063
  - Mean predicted: -0.002934
  - Mean actual: 0.000023
  - Mean divergence: -0.002957
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“Š CRYPTO_110 (Index: 110) - INDIVIDUALLY MASKED:
  - Correlation: -0.0314
  - Mean predicted: -0.000734
  - Mean actual: 0.000015
  - Mean divergence: -0.000749
  - Data points: 499
  âŒ No meaningful cross-sectional predictive relationship

ðŸ“ˆ SUMMARY STATISTICS (INDIVIDUAL MASKING, EVENLY SPACED SAMPLES):
======================================================================
ðŸŒ ALL CRYPTOS (111 total) - INDIVIDUAL MASKING RESULTS:
  - Mean correlation: 0.0061
  - Max correlation: 0.1702
  - Min correlation: -0.1252
  - Strong signals (|corr| > 0.1): 9 (8.1%)
  - Weak signals (0.05 < |corr| â‰¤ 0.1): 35 (31.5%)
  - No signal (|corr| â‰¤ 0.05): 67 (60.4%)
```


# Analysis code
```rust
// main.rs
pub mod dataset;
mod financial_bert;
use std::process::exit;

use candle_bert_time_series::batcher::Batcher;
use dataset::load_and_prepare_data;
use financial_bert::{Config, FinancialTransformerForMaskedRegression};

use candle_core::{scalar::TensorOrScalar, DType, Device, Result, Tensor};
use candle_nn::{loss, Optimizer, VarBuilder, VarMap};

// --- Configuration ---
// NUM_TIME_SERIES will be determined dynamically from the data
const SEQUENCE_LENGTH: usize = 240; // 240
const MODEL_DIMS: usize = 384; // 384
const NUM_LAYERS: usize = 12;
const NUM_HEADS: usize = 12;
const NUM_EPOCHS: usize = 32;
const LEARNING_RATE: f64 = 1e-4;
const MASK_PROB: f32 = 0.15;
const CRYPTO_MASK_PROB: f32 = 0.15; // Percentage of cryptos to mask in crypto-column masking
const BATCH_SIZE: usize = 320;   // Entire dataset rn: 1594848

// Data file path - update this to point to your parquet file
const DATA_PATH: &str = "/home/i3/Downloads/transformed_dataset.parquet";

// --- Data Generation and Preparation ---

/// Corrected and simplified masking function for 3D batched input.
fn mask_data(
    input: &Tensor, // Expects a 3D tensor: [BATCH_SIZE, SEQUENCE_LENGTH, NUM_TIME_SERIES] -> [32, 120, 190]
    device: &Device,
) -> Result<(Tensor, Tensor, Tensor)> {
    let shape = input.shape();
    let rand_mask = Tensor::rand(0f32, 1f32, shape, device)?;
    // `mask` is a boolean tensor of shape [32, 120, 190]
    let mask = (rand_mask.lt(MASK_PROB))?;
    let zeros = Tensor::zeros(shape, input.dtype(), device)?;

    // `masked_select` correctly gathers only the masked values into a 1D tensor.
    // Shape: [num_masked_elements] (flattened from all batch elements)
    let true_labels = mask.where_cond(input, &zeros)?;

    // Zero out the values in the input where the mask is true.
    // This preserves the original shape of the input.
    // Shape: [32, 120, 190]
    // 1. Create a tensor of ones with the same shape as the mask.
    //    The `lt` operation produces a U8 tensor, so we use DType::U8.
    let ones = Tensor::ones(shape, DType::U8, device)?;
    // 2. Subtract the mask from ones. If mask is [1, 0, 1], result is [0, 1, 0].
    let inverted_mask = ones.sub(&mask)?;
    // 3. Use this inverted mask to create the model input.
    let masked_input = input.broadcast_mul(&inverted_mask.to_dtype(DType::F32)?)?;

    Ok((masked_input, true_labels, mask))
}



/// Masks entire cryptocurrencies (15% of them) rather than random data points.
/// This is much closer to the inference task where we predict one crypto's movements
/// based on other cryptos' movements.
fn mask_data_crypto_columns(
    input: &Tensor, // Expects a 3D tensor: [BATCH_SIZE, SEQUENCE_LENGTH, NUM_TIME_SERIES] -> [32, 120, 190]
    device: &Device,
) -> Result<(Tensor, Tensor, Tensor)> {
    let shape = input.shape();
    let batch_size = shape.dims()[0];
    let sequence_length = shape.dims()[1];
    let num_cryptos = shape.dims()[2];

    // Calculate how many cryptos to mask (15% of total)
    let num_cryptos_to_mask = ((num_cryptos as f32) * CRYPTO_MASK_PROB).ceil() as usize;

    // Create a random permutation to select which cryptos to mask
    let mut crypto_indices: Vec<usize> = (0..num_cryptos).collect();

    // Simple random shuffle using tensor operations
    let rand_values = Tensor::rand(0f32, 1f32, &[num_cryptos], device)?;
    let rand_vec: Vec<f32> = rand_values.to_vec1()?;

    // Sort indices by random values to create a shuffle
    crypto_indices.sort_by(|&a, &b| rand_vec[a].partial_cmp(&rand_vec[b]).unwrap());

    // Take the first num_cryptos_to_mask indices as the ones to mask
    let cryptos_to_mask = &crypto_indices[..num_cryptos_to_mask];

    // Create a boolean mask for which cryptos to mask
    // Shape: [NUM_TIME_SERIES]
    let mut crypto_mask_vec = vec![0u8; num_cryptos];
    for &crypto_idx in cryptos_to_mask {
        crypto_mask_vec[crypto_idx] = 1;
    }
    let crypto_mask = Tensor::from_vec(crypto_mask_vec, &[num_cryptos], device)?;

    // Broadcast the crypto mask to full tensor shape
    // Shape: [1, 1, NUM_TIME_SERIES] -> [BATCH_SIZE, SEQUENCE_LENGTH, NUM_TIME_SERIES]
    let crypto_mask_3d = crypto_mask.unsqueeze(0)?.unsqueeze(0)?;
    let mask = crypto_mask_3d.broadcast_as(shape)?;

    let zeros = Tensor::zeros(shape, input.dtype(), device)?;

    // Extract true labels for masked positions
    let true_labels = mask.where_cond(input, &zeros)?;

    // Create masked input by zeroing out the masked crypto columns
    let ones = Tensor::ones(shape, DType::U8, device)?;
    let inverted_mask = ones.sub(&mask)?;
    let masked_input = input.broadcast_mul(&inverted_mask.to_dtype(DType::F32)?)?;

    Ok((masked_input, true_labels, mask.to_dtype(DType::U8)?))
}

fn mask_data_last_col(
    input: &Tensor, // Expects a 3D tensor: [BATCH_SIZE, SEQUENCE_LENGTH, NUM_TIME_SERIES] -> [32, 120, 190]
    device: &Device,
) -> Result<(Tensor, Tensor, Tensor)> {
    let shape = input.shape();

    // Create mask only for the newest minute (last time step in sequence)
    // Shape: [batch_size, 1, num_time_series] -> [32, 1, 190]
    let last_timestep_shape = &[shape.dims()[0], 1, shape.dims()[2]];
    let last_timestep_mask = Tensor::ones(last_timestep_shape, DType::F32, device)?;

    // Create full mask tensor with zeros everywhere except the last timestep
    let mut full_mask = Tensor::zeros(shape, DType::F32, device)?;
    // Set the last timestep (index 119 for sequence length 120) to our random mask
    let last_idx = shape.dims()[1] - 1; // 119 for sequence length 120

    // Use narrow and cat to insert the mask at the last timestep
    let before_last = full_mask.narrow(1, 0, last_idx)?;
    let after_last = if last_idx + 1 < shape.dims()[1] {
        Some(full_mask.narrow(1, last_idx + 1, shape.dims()[1] - last_idx - 1)?)
    } else {
        None
    };

    full_mask = if let Some(after) = after_last {
        Tensor::cat(&[&before_last, &last_timestep_mask, &after], 1)?
    } else {
        Tensor::cat(&[&before_last, &last_timestep_mask], 1)?
    };

    // Convert to U8 for boolean operations
    let full_mask = full_mask.to_dtype(DType::U8)?;

    let zeros = Tensor::zeros(shape, input.dtype(), device)?;

    // `masked_select` correctly gathers only the masked values from the last timestep.
    // Shape: [num_masked_elements] (only from the newest minute across all batches)
    let true_labels = full_mask.where_cond(input, &zeros)?;

    // Zero out the values in the input where the mask is true (only in the newest minute).
    // This preserves the original shape of the input.
    // Shape: [32, 120, 190]
    // 1. Create a tensor of ones with the same shape as the full mask.
    let ones = Tensor::ones(shape, DType::U8, device)?;
    // 2. Subtract the mask from ones. If mask is [1, 0, 1], result is [0, 1, 0].
    let inverted_mask = ones.sub(&full_mask)?;
    // 3. Use this inverted mask to create the model input.
    let masked_input = input.broadcast_mul(&inverted_mask.to_dtype(DType::F32)?)?;

    Ok((masked_input, true_labels, full_mask))
}

/// Evaluate the model on a dataset (validation or test) without updating weights
fn evaluate_model(
    model: &FinancialTransformerForMaskedRegression,
    data: &Tensor,
    device: &Device,
    dataset_name: &str,
    masking_fn: fn(&Tensor, &Device) -> Result<(Tensor, Tensor, Tensor)>,
) -> Result<f32> {
    let mut total_loss = 0.0;
    let mut batch_count = 0;

    let mut batcher = Batcher::new(data, SEQUENCE_LENGTH, BATCH_SIZE);

    while let Some(batch_result) = batcher.next() {
        let batch = batch_result?;

        // Apply masking
        let (masked_input, true_labels, mask) = mask_data(&batch, device)?;

        // Forward pass (no gradient computation needed for evaluation)
        let predictions = model.forward(&masked_input)?;

        // Calculate loss and sign accuracy
        let zeros = Tensor::zeros(predictions.shape(), predictions.dtype(), device)?;
        let predicted_values = mask.where_cond(&predictions, &zeros)?;
        let loss = loss::mse(&predicted_values, &true_labels)?;

        total_loss += loss.to_scalar::<f32>()?;
        batch_count += 1;
    }

    let avg_loss = if batch_count > 0 { total_loss / batch_count as f32 } else { 0.0 };

    println!("  {} Loss: {:.10} (averaged over {} batches)", dataset_name, avg_loss, batch_count);

    Ok(avg_loss)
}

// --- The Main Training Function ---

fn main() -> Result<()> {
    let device = Device::cuda_if_available(0)?;
    println!("Training on device: {:?}", device);

    // --- Data Loading First to Determine Dimensions ---
    println!("Loading cryptocurrency data...");
    let (full_data_sequence, num_time_series) = load_and_prepare_data(DATA_PATH, &device)?;
    let total_timesteps = full_data_sequence.dims()[0];

    // Split data into train (70%), validation (15%), test (15%)
    // NOTE: This split logic is replicated in backtest::extract_test_split() to prevent data leakage
    let train_split = (total_timesteps as f32 * 0.7) as usize;
    let val_split = (total_timesteps as f32 * 0.85) as usize;

    let train_data = full_data_sequence.narrow(0, 0, train_split)?;
    let val_data = full_data_sequence.narrow(0, train_split, val_split - train_split)?;
    let test_data = full_data_sequence.narrow(0, val_split, total_timesteps - val_split)?;

    println!("Data splits - Train: {}, Validation: {}, Test: {}",
             train_data.dims()[0], val_data.dims()[0], test_data.dims()[0]);

    println!("Detected {} cryptocurrencies in the dataset", num_time_series);

    // --- Model and Optimizer Setup ---
    let config = Config {
        num_time_series,
        hidden_size: MODEL_DIMS,
        num_hidden_layers: NUM_LAYERS,
        num_attention_heads: NUM_HEADS,
        intermediate_size: MODEL_DIMS * 4,
        hidden_act: financial_bert::HiddenAct::Gelu,
        hidden_dropout_prob: 0.1,
        max_position_embeddings: SEQUENCE_LENGTH,
        initializer_range: 0.02,
        layer_norm_eps: 1e-12,
        position_embedding_type: financial_bert::PositionEmbeddingType::Absolute,
        use_cache: false,
        model_type: Some("financial_transformer".to_string()),
    };
    let mut varmap = VarMap::new();
    let vb = VarBuilder::from_varmap(&varmap, DType::F32, &device);
    let model = FinancialTransformerForMaskedRegression::load(vb, &config)?;

    /*
    let checkpoint_path = format!("current_model_large.safetensors");
    varmap.load(checkpoint_path.clone())?;
    println!("Loaded checkpoint: {}", checkpoint_path);
    */

    let adamw_params = candle_nn::ParamsAdamW {
        lr: LEARNING_RATE,
        weight_decay: 0.02,
        ..Default::default()
    };
    let mut optimizer = candle_nn::AdamW::new(varmap.all_vars(), adamw_params)?;



    /*
    println!("Running test...");    
    let val_loss = evaluate_model(&model, &val_data, &device, "Val", mask_data_last_col)?;
    println!("Last Col Val Loss:   {:.10}", val_loss);
    let test_loss = evaluate_model(&model, &test_data, &device, "Test", mask_data_last_col)?;
    println!("Last Col Test Loss: {:.10}", test_loss);

    let val_loss = evaluate_model(&model, &val_data, &device, "Val", mask_data)?;
    println!(" Val Loss:   {:.10}", val_loss);
    let test_loss = evaluate_model(&model, &test_data, &device, "Test", mask_data)?;
    println!(" Test Loss: {:.10}", test_loss);
    
    return Ok(());
    */

    println!("Starting training...");
    for epoch in 0..NUM_EPOCHS {
        println!("\n--- Epoch {} ---", epoch + 1);

        // --- TRAINING PHASE: Process all batches in the training set ---
        let mut epoch_train_loss = 0.0;
        let mut epoch_sign_loss = 0.0;
        let mut train_batch_count = 0;

        let mut train_batcher = Batcher::new(&train_data, SEQUENCE_LENGTH, BATCH_SIZE);
        let mut batch_index = 0;

        while let Some(batch_result) = train_batcher.next() {
            let batch = batch_result?;

            // `masked_input` Shape: [32, 120, 190]
            // `true_labels` Shape: [num_masked] (1D, flattened from all batch elements)
            // `mask` Shape: [32, 120, 190] (boolean)
            let (masked_input, true_labels, mask) = mask_data_crypto_columns(&batch, &device)?;

            // --- FORWARD PASS ---
            // The model expects a 3D tensor: (batch_size, seq_len, features).
            // The batch is already properly shaped, no need to unsqueeze.
            // `model_input` Shape: [32, 120, 190]
            let model_input = masked_input;

            // `predictions` will have the same shape as the input.
            // `predictions` Shape: [32, 120, 190]
            let predictions = model.forward(&model_input)?;

            // --- LOSS CALCULATION ---
            // To compare with our labels, we must isolate the predictions at the masked positions.
            // Use the same boolean mask to select the predicted values.
            // This flattens the tensor, matching the shape of `true_labels`.
            // `predicted_values` Shape: [num_masked] (1D, flattened from all batch elements)
            let zeros = Tensor::zeros(predictions.shape(), predictions.dtype(), &device)?;
            let predicted_values = mask.where_cond(&predictions, &zeros)?;

            // Now we can compare the two 1D tensors.
            let loss_mse = loss::mse(&predicted_values, &true_labels)?;
            let loss = loss_mse;

            // Calculate sign accuracy and sign loss to improve directional correlation
            //let correct_signs = (predicted_values.sign()? * true_labels.sign()?)?.eq(1.0)?.to_dtype(DType::F32)?.sum_all()?;
            //let loss_sign = predicted_values.ones_like()?.sum_all()?.div(&correct_signs)?;

            // Sign loss: penalize incorrect directional predictions
            // Convert sign agreement to loss (1.0 - accuracy gives us the error rate)

            // Combine MSE loss with sign loss for better directional correlation
            // Weight the sign loss to emphasize directional accuracy
            //let sign_weight = Tensor::new(0.05f32, &device)?;
            // let mse_weight = Tensor::new(0.95f32, &device)?;
            // let loss = loss_mse.mul(&mse_weight)?.add(&loss_sign.mul(&sign_weight)?)?;

            /*
            // Transformer learnign rate warmup
            let num_batches_per_epoch = train_batcher.clone().count() as usize;
            let total_steps = NUM_EPOCHS * num_batches_per_epoch;
            let warmup_steps = 1000;
            let current_step = epoch * num_batches_per_epoch + batch_index;
            batch_index += 1;

            let new_lr = if current_step < warmup_steps {
                // Linear warmup
                LEARNING_RATE * (current_step as f64 / warmup_steps as f64)
            } else {
                // Cosine decay (example)
                LEARNING_RATE * 0.5 * (1.0 + (std::f64::consts::PI * (current_step - warmup_steps) as f64 / (total_steps - warmup_steps) as f64).cos())
            };
            optimizer.set_learning_rate(new_lr);
            */

            // --- BACKWARD PASS ---
            optimizer.backward_step(&loss)?;

            // Accumulate training loss and sign accuracy
            epoch_train_loss += loss.to_scalar::<f32>()?;
            train_batch_count += 1;

            if train_batch_count % 100 == 0 {
                println!("  Batch {}% processed", (train_batch_count as f32 / (1594848.0 / BATCH_SIZE as f32))*100.0);
            }
        }

        // Calculate average training loss and sign accuracy for this epoch
        let avg_train_loss = if train_batch_count > 0 {
            epoch_train_loss / train_batch_count as f32
        } else {
            0.0
        };
        
        println!("Training completed: {} batches processed", train_batch_count);
        println!("  Training Loss: {:.10} (averaged over {} batches)", avg_train_loss, train_batch_count);
        
        // --- VALIDATION PHASE ---
        println!("Running validation...");
        let val_loss = evaluate_model(&model, &val_data, &device, "Validation", mask_data)?;

        // --- EPOCH SUMMARY ---
        println!("Epoch {} Summary:", epoch + 1);
        println!("  Train Loss: {:.10}", avg_train_loss);
        println!("  Val Loss:   {:.10}", val_loss);
        
        // Save model checkpoint after each epoch
        let checkpoint_path = format!("current_model_large.safetensors");
        varmap.save(&checkpoint_path)?;
        println!("Saved checkpoint to: {}", checkpoint_path);
    }

    // --- TEST PHASE ---
    println!("Running test...");
    let val_loss = evaluate_model(&model, &val_data, &device, "Val", mask_data_last_col)?;
    println!("Last Col Val Loss:   {:.10}", val_loss);
    let test_loss = evaluate_model(&model, &test_data, &device, "Test", mask_data_last_col)?;
    println!("Last Col Test Loss: {:.10}", test_loss);

    let val_loss = evaluate_model(&model, &val_data, &device, "Val", mask_data)?;
    println!(" Val Loss:   {:.10}", val_loss);
    let test_loss = evaluate_model(&model, &test_data, &device, "Test", mask_data)?;
    println!(" Test Loss: {:.10}", test_loss);

    Ok(())
}

```

